{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson A5: Async Programming\n",
    "\n",
    "**Duration**: 150-180 minutes  \n",
    "**Stage**: Advanced (Mastery)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "1. Understand async/await syntax and Future trait\n",
    "2. Work with async runtimes (conceptually)\n",
    "3. Handle async I/O operations\n",
    "4. Combine async programming with error handling\n",
    "5. Design async systems and understand their benefits\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Prerequisite Review\n",
    "\n",
    "**Quick Check**: From our previous lessons:\n",
    "\n",
    "1. How do threads communicate using channels?\n",
    "2. What's the purpose of Arc<T> and Mutex<T>?\n",
    "3. What are Send and Sync traits?\n",
    "4. How do you handle errors in concurrent code?\n",
    "\n",
    "**Answers**: 1) mpsc channels for message passing, 2) Shared ownership and thread-safe mutation, 3) Thread safety markers, 4) Result types and proper error propagation\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Key Concepts\n",
    "\n",
    "### Async Programming Model\n",
    "\n",
    "**Future Trait**: Represents a value that will be available in the future\n",
    "**async/await**: Syntax for writing asynchronous code\n",
    "**Runtime**: Executes async tasks (Tokio, async-std)\n",
    "**Cooperative Multitasking**: Tasks yield control voluntarily\n",
    "**Non-blocking I/O**: Operations don't block the thread\n",
    "\n",
    "### Async vs Threads\n",
    "\n",
    "- **Async**: Lightweight tasks, single-threaded by default, great for I/O\n",
    "- **Threads**: OS-level parallelism, good for CPU-intensive work\n",
    "- **Hybrid**: Combine both for optimal performance\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¬ Live Code Exploration\n",
    "\n",
    "### Basic Async Functions and Futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// Basic async functions and futures\n",
    "// Note: This is conceptual code for learning - evcxr doesn't support async runtimes\n",
    "\n",
    "use std::future::Future;\n",
    "use std::pin::Pin;\n",
    "use std::task::{Context, Poll};\n",
    "use std::time::{Duration, Instant};\n",
    "\n",
    "// Simple async function\n",
    "async fn simple_async_function() -> String {\n",
    "    \"Hello from async function!\".to_string()\n",
    "}\n",
    "\n",
    "// Async function with delay simulation\n",
    "async fn delayed_computation(delay_ms: u64, value: i32) -> i32 {\n",
    "    // In real async code, this would be:\n",
    "    // tokio::time::sleep(Duration::from_millis(delay_ms)).await;\n",
    "    \n",
    "    println!(\"Starting computation with {}ms delay for value {}\", delay_ms, value);\n",
    "    \n",
    "    // Simulate async work\n",
    "    value * 2\n",
    "}\n",
    "\n",
    "// Custom Future implementation\n",
    "struct DelayedValue {\n",
    "    value: i32,\n",
    "    delay: Duration,\n",
    "    start_time: Option<Instant>,\n",
    "}\n",
    "\n",
    "impl DelayedValue {\n",
    "    fn new(value: i32, delay: Duration) -> Self {\n",
    "        DelayedValue {\n",
    "            value,\n",
    "            delay,\n",
    "            start_time: None,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "impl Future for DelayedValue {\n",
    "    type Output = i32;\n",
    "    \n",
    "    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n",
    "        let start_time = self.start_time.get_or_insert_with(Instant::now);\n",
    "        \n",
    "        if start_time.elapsed() >= self.delay {\n",
    "            println!(\"DelayedValue ready: {}\", self.value);\n",
    "            Poll::Ready(self.value)\n",
    "        } else {\n",
    "            // In a real runtime, we'd register a waker\n",
    "            cx.waker().wake_by_ref();\n",
    "            Poll::Pending\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async error handling\n",
    "#[derive(Debug)]\n",
    "enum AsyncError {\n",
    "    NetworkError(String),\n",
    "    TimeoutError,\n",
    "    ParseError(String),\n",
    "}\n",
    "\n",
    "impl std::fmt::Display for AsyncError {\n",
    "    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n",
    "        match self {\n",
    "            AsyncError::NetworkError(msg) => write!(f, \"Network error: {}\", msg),\n",
    "            AsyncError::TimeoutError => write!(f, \"Operation timed out\"),\n",
    "            AsyncError::ParseError(msg) => write!(f, \"Parse error: {}\", msg),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "impl std::error::Error for AsyncError {}\n",
    "\n",
    "// Async function with error handling\n",
    "async fn fetch_data(url: &str) -> Result<String, AsyncError> {\n",
    "    println!(\"Fetching data from: {}\", url);\n",
    "    \n",
    "    // Simulate different outcomes\n",
    "    if url.contains(\"error\") {\n",
    "        Err(AsyncError::NetworkError(\"Connection failed\".to_string()))\n",
    "    } else if url.contains(\"timeout\") {\n",
    "        Err(AsyncError::TimeoutError)\n",
    "    } else {\n",
    "        Ok(format!(\"Data from {}\", url))\n",
    "    }\n",
    "}\n",
    "\n",
    "// Combining multiple async operations\n",
    "async fn process_multiple_urls(urls: Vec<&str>) -> Vec<Result<String, AsyncError>> {\n",
    "    let mut results = Vec::new();\n",
    "    \n",
    "    for url in urls {\n",
    "        let result = fetch_data(url).await;\n",
    "        results.push(result);\n",
    "    }\n",
    "    \n",
    "    results\n",
    "}\n",
    "\n",
    "fn async_concepts_demo() {\n",
    "    println!(\"=== Async Programming Concepts ===\");\n",
    "    \n",
    "    // Note: In a real async environment, you would use:\n",
    "    // #[tokio::main]\n",
    "    // async fn main() {\n",
    "    //     let result = simple_async_function().await;\n",
    "    //     println!(\"Result: {}\", result);\n",
    "    // }\n",
    "    \n",
    "    println!(\"Async function concepts:\");\n",
    "    println!(\"- async fn returns impl Future<Output = T>\");\n",
    "    println!(\"- .await suspends execution until Future is ready\");\n",
    "    println!(\"- Futures are lazy - they don't run until awaited\");\n",
    "    println!(\"- Runtime manages task scheduling and I/O\");\n",
    "    \n",
    "    // Demonstrate Future trait concepts\n",
    "    println!(\"\\nCustom Future implementation:\");\n",
    "    let delayed = DelayedValue::new(42, Duration::from_millis(100));\n",
    "    println!(\"Created DelayedValue future (not yet executed)\");\n",
    "    \n",
    "    // Error handling patterns\n",
    "    println!(\"\\nAsync error handling patterns:\");\n",
    "    println!(\"- Use Result<T, E> for fallible operations\");\n",
    "    println!(\"- ? operator works with async functions\");\n",
    "    println!(\"- Combine with try_join! for concurrent error handling\");\n",
    "}\n",
    "\n",
    "async_concepts_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async Patterns and Combinators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// Async patterns and combinators (conceptual)\n",
    "\n",
    "use std::collections::HashMap;\n",
    "\n",
    "// Async data structures\n",
    "#[derive(Debug, Clone)]\n",
    "struct AsyncTask {\n",
    "    id: u32,\n",
    "    name: String,\n",
    "    duration_ms: u64,\n",
    "    dependencies: Vec<u32>,\n",
    "}\n",
    "\n",
    "impl AsyncTask {\n",
    "    fn new(id: u32, name: String, duration_ms: u64) -> Self {\n",
    "        AsyncTask {\n",
    "            id,\n",
    "            name,\n",
    "            duration_ms,\n",
    "            dependencies: Vec::new(),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn with_dependencies(mut self, deps: Vec<u32>) -> Self {\n",
    "        self.dependencies = deps;\n",
    "        self\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async task executor (conceptual)\n",
    "struct AsyncTaskExecutor {\n",
    "    tasks: HashMap<u32, AsyncTask>,\n",
    "    completed: HashMap<u32, String>,\n",
    "}\n",
    "\n",
    "impl AsyncTaskExecutor {\n",
    "    fn new() -> Self {\n",
    "        AsyncTaskExecutor {\n",
    "            tasks: HashMap::new(),\n",
    "            completed: HashMap::new(),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn add_task(&mut self, task: AsyncTask) {\n",
    "        self.tasks.insert(task.id, task);\n",
    "    }\n",
    "    \n",
    "    // Simulate async task execution\n",
    "    async fn execute_task(&mut self, task_id: u32) -> Result<String, String> {\n",
    "        let task = self.tasks.get(&task_id)\n",
    "            .ok_or_else(|| format!(\"Task {} not found\", task_id))?;\n",
    "        \n",
    "        // Check dependencies\n",
    "        for dep_id in &task.dependencies {\n",
    "            if !self.completed.contains_key(dep_id) {\n",
    "                return Err(format!(\"Dependency {} not completed for task {}\", dep_id, task_id));\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        println!(\"Executing task {}: {} ({}ms)\", task.id, task.name, task.duration_ms);\n",
    "        \n",
    "        // In real async code:\n",
    "        // tokio::time::sleep(Duration::from_millis(task.duration_ms)).await;\n",
    "        \n",
    "        let result = format!(\"Completed: {}\", task.name);\n",
    "        self.completed.insert(task_id, result.clone());\n",
    "        \n",
    "        Ok(result)\n",
    "    }\n",
    "    \n",
    "    // Execute all tasks respecting dependencies\n",
    "    async fn execute_all(&mut self) -> Vec<Result<String, String>> {\n",
    "        let mut results = Vec::new();\n",
    "        let task_ids: Vec<u32> = self.tasks.keys().cloned().collect();\n",
    "        \n",
    "        // Simple sequential execution (in real code, use proper dependency resolution)\n",
    "        for task_id in task_ids {\n",
    "            let result = self.execute_task(task_id).await;\n",
    "            results.push(result);\n",
    "        }\n",
    "        \n",
    "        results\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async stream processing (conceptual)\n",
    "struct AsyncDataProcessor {\n",
    "    name: String,\n",
    "}\n",
    "\n",
    "impl AsyncDataProcessor {\n",
    "    fn new(name: String) -> Self {\n",
    "        AsyncDataProcessor { name }\n",
    "    }\n",
    "    \n",
    "    // Process data asynchronously\n",
    "    async fn process_item(&self, item: i32) -> Result<i32, String> {\n",
    "        println!(\"{}: Processing item {}\", self.name, item);\n",
    "        \n",
    "        // Simulate processing time and potential errors\n",
    "        if item < 0 {\n",
    "            Err(format!(\"Invalid item: {}\", item))\n",
    "        } else {\n",
    "            Ok(item * 2)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Process multiple items\n",
    "    async fn process_batch(&self, items: Vec<i32>) -> Vec<Result<i32, String>> {\n",
    "        let mut results = Vec::new();\n",
    "        \n",
    "        for item in items {\n",
    "            let result = self.process_item(item).await;\n",
    "            results.push(result);\n",
    "        }\n",
    "        \n",
    "        results\n",
    "    }\n",
    "    \n",
    "    // Concurrent processing (conceptual)\n",
    "    async fn process_concurrent(&self, items: Vec<i32>) -> Vec<Result<i32, String>> {\n",
    "        println!(\"{}: Starting concurrent processing of {} items\", self.name, items.len());\n",
    "        \n",
    "        // In real async code with tokio:\n",
    "        // let futures: Vec<_> = items.into_iter()\n",
    "        //     .map(|item| self.process_item(item))\n",
    "        //     .collect();\n",
    "        // \n",
    "        // futures::future::join_all(futures).await\n",
    "        \n",
    "        // For demonstration, process sequentially\n",
    "        self.process_batch(items).await\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async HTTP client simulation\n",
    "struct AsyncHttpClient {\n",
    "    base_url: String,\n",
    "    timeout_ms: u64,\n",
    "}\n",
    "\n",
    "impl AsyncHttpClient {\n",
    "    fn new(base_url: String, timeout_ms: u64) -> Self {\n",
    "        AsyncHttpClient { base_url, timeout_ms }\n",
    "    }\n",
    "    \n",
    "    async fn get(&self, path: &str) -> Result<String, AsyncError> {\n",
    "        let url = format!(\"{}/{}\", self.base_url, path);\n",
    "        println!(\"GET {}\", url);\n",
    "        \n",
    "        // Simulate network request\n",
    "        if path.contains(\"slow\") {\n",
    "            // Simulate timeout\n",
    "            Err(AsyncError::TimeoutError)\n",
    "        } else if path.contains(\"error\") {\n",
    "            Err(AsyncError::NetworkError(\"404 Not Found\".to_string()))\n",
    "        } else {\n",
    "            Ok(format!(\"Response from {}\", url))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    async fn post(&self, path: &str, data: &str) -> Result<String, AsyncError> {\n",
    "        let url = format!(\"{}/{}\", self.base_url, path);\n",
    "        println!(\"POST {} with data: {}\", url, data);\n",
    "        \n",
    "        // Simulate POST request\n",
    "        Ok(format!(\"Posted to {}: {}\", url, data))\n",
    "    }\n",
    "    \n",
    "    // Batch requests\n",
    "    async fn batch_get(&self, paths: Vec<&str>) -> Vec<Result<String, AsyncError>> {\n",
    "        let mut results = Vec::new();\n",
    "        \n",
    "        for path in paths {\n",
    "            let result = self.get(path).await;\n",
    "            results.push(result);\n",
    "        }\n",
    "        \n",
    "        results\n",
    "    }\n",
    "}\n",
    "\n",
    "fn async_patterns_demo() {\n",
    "    println!(\"\\n=== Async Patterns and Combinators ===\");\n",
    "    \n",
    "    // Task execution patterns\n",
    "    println!(\"Async task execution patterns:\");\n",
    "    println!(\"- Sequential: await each task in order\");\n",
    "    println!(\"- Concurrent: join_all for parallel execution\");\n",
    "    println!(\"- Racing: select! for first completion\");\n",
    "    println!(\"- Streaming: process data as it arrives\");\n",
    "    \n",
    "    // Error handling patterns\n",
    "    println!(\"\\nAsync error handling:\");\n",
    "    println!(\"- try_join! fails fast on first error\");\n",
    "    println!(\"- join_all collects all results\");\n",
    "    println!(\"- timeout() adds time limits\");\n",
    "    println!(\"- retry() for resilient operations\");\n",
    "    \n",
    "    // Common async patterns\n",
    "    println!(\"\\nCommon async patterns:\");\n",
    "    println!(\"- Producer/Consumer with async channels\");\n",
    "    println!(\"- Connection pooling for resources\");\n",
    "    println!(\"- Circuit breaker for fault tolerance\");\n",
    "    println!(\"- Rate limiting for API calls\");\n",
    "    \n",
    "    // Performance considerations\n",
    "    println!(\"\\nPerformance considerations:\");\n",
    "    println!(\"- Async is great for I/O-bound tasks\");\n",
    "    println!(\"- Use threads for CPU-intensive work\");\n",
    "    println!(\"- Avoid blocking operations in async code\");\n",
    "    println!(\"- Consider task spawning overhead\");\n",
    "}\n",
    "\n",
    "async_patterns_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Guided Practice\n",
    "\n",
    "### Exercise 1: Async Web Service Simulation\n",
    "\n",
    "Create a simulation of an async web service with multiple endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// TODO: Complete the async web service simulation\n",
    "\n",
    "use std::collections::HashMap;\n",
    "use std::time::{Duration, Instant};\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "struct Request {\n",
    "    id: u32,\n",
    "    method: String,\n",
    "    path: String,\n",
    "    body: Option<String>,\n",
    "    timestamp: Instant,\n",
    "}\n",
    "\n",
    "impl Request {\n",
    "    fn new(id: u32, method: String, path: String) -> Self {\n",
    "        Request {\n",
    "            id,\n",
    "            method,\n",
    "            path,\n",
    "            body: None,\n",
    "            timestamp: Instant::now(),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn with_body(mut self, body: String) -> Self {\n",
    "        self.body = Some(body);\n",
    "        self\n",
    "    }\n",
    "}\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "struct Response {\n",
    "    status: u16,\n",
    "    body: String,\n",
    "    processing_time_ms: u64,\n",
    "}\n",
    "\n",
    "impl Response {\n",
    "    fn ok(body: String, processing_time_ms: u64) -> Self {\n",
    "        Response {\n",
    "            status: 200,\n",
    "            body,\n",
    "            processing_time_ms,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn not_found(processing_time_ms: u64) -> Self {\n",
    "        Response {\n",
    "            status: 404,\n",
    "            body: \"Not Found\".to_string(),\n",
    "            processing_time_ms,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn error(message: String, processing_time_ms: u64) -> Self {\n",
    "        Response {\n",
    "            status: 500,\n",
    "            body: message,\n",
    "            processing_time_ms,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async web service\n",
    "struct AsyncWebService {\n",
    "    name: String,\n",
    "    data_store: HashMap<String, String>,\n",
    "    request_count: u32,\n",
    "}\n",
    "\n",
    "impl AsyncWebService {\n",
    "    fn new(name: String) -> Self {\n",
    "        let mut data_store = HashMap::new();\n",
    "        data_store.insert(\"users/1\".to_string(), \"User 1 Data\".to_string());\n",
    "        data_store.insert(\"users/2\".to_string(), \"User 2 Data\".to_string());\n",
    "        data_store.insert(\"posts/1\".to_string(), \"Post 1 Content\".to_string());\n",
    "        \n",
    "        AsyncWebService {\n",
    "            name,\n",
    "            data_store,\n",
    "            request_count: 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Handle GET requests\n",
    "    async fn handle_get(&mut self, path: &str) -> Response {\n",
    "        let start_time = Instant::now();\n",
    "        \n",
    "        println!(\"{}: Handling GET {}\", self.name, path);\n",
    "        \n",
    "        // Simulate processing time based on path\n",
    "        let processing_delay = match path {\n",
    "            p if p.contains(\"slow\") => 200,\n",
    "            p if p.contains(\"users\") => 50,\n",
    "            p if p.contains(\"posts\") => 30,\n",
    "            _ => 10,\n",
    "        };\n",
    "        \n",
    "        // In real async code: tokio::time::sleep(Duration::from_millis(processing_delay)).await;\n",
    "        \n",
    "        let processing_time = start_time.elapsed().as_millis() as u64 + processing_delay;\n",
    "        \n",
    "        // Simulate different responses\n",
    "        if path.contains(\"error\") {\n",
    "            Response::error(\"Internal Server Error\".to_string(), processing_time)\n",
    "        } else if let Some(data) = self.data_store.get(path) {\n",
    "            Response::ok(data.clone(), processing_time)\n",
    "        } else {\n",
    "            Response::not_found(processing_time)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Handle POST requests\n",
    "    async fn handle_post(&mut self, path: &str, body: &str) -> Response {\n",
    "        let start_time = Instant::now();\n",
    "        \n",
    "        println!(\"{}: Handling POST {} with body: {}\", self.name, path, body);\n",
    "        \n",
    "        // Simulate processing\n",
    "        let processing_delay = 100; // POST operations are typically slower\n",
    "        let processing_time = start_time.elapsed().as_millis() as u64 + processing_delay;\n",
    "        \n",
    "        if path.contains(\"error\") {\n",
    "            Response::error(\"Failed to create resource\".to_string(), processing_time)\n",
    "        } else {\n",
    "            // Store the data\n",
    "            self.data_store.insert(path.to_string(), body.to_string());\n",
    "            Response::ok(format!(\"Created resource at {}\", path), processing_time)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Main request handler\n",
    "    async fn handle_request(&mut self, request: Request) -> Response {\n",
    "        self.request_count += 1;\n",
    "        \n",
    "        println!(\"\\n[Request {}] {} {} (ID: {})\", \n",
    "                self.request_count, request.method, request.path, request.id);\n",
    "        \n",
    "        let response = match request.method.as_str() {\n",
    "            \"GET\" => self.handle_get(&request.path).await,\n",
    "            \"POST\" => {\n",
    "                let body = request.body.as_deref().unwrap_or(\"\");\n",
    "                self.handle_post(&request.path, body).await\n",
    "            }\n",
    "            _ => Response::error(\"Method not allowed\".to_string(), 1),\n",
    "        };\n",
    "        \n",
    "        println!(\"[Response {}] Status: {}, Time: {}ms\", \n",
    "                request.id, response.status, response.processing_time_ms);\n",
    "        \n",
    "        response\n",
    "    }\n",
    "    \n",
    "    // Process multiple requests\n",
    "    async fn process_requests(&mut self, requests: Vec<Request>) -> Vec<Response> {\n",
    "        let mut responses = Vec::new();\n",
    "        \n",
    "        println!(\"\\nðŸš€ Processing {} requests...\", requests.len());\n",
    "        \n",
    "        for request in requests {\n",
    "            let response = self.handle_request(request).await;\n",
    "            responses.push(response);\n",
    "        }\n",
    "        \n",
    "        responses\n",
    "    }\n",
    "    \n",
    "    // Concurrent request processing (conceptual)\n",
    "    async fn process_concurrent(&mut self, requests: Vec<Request>) -> Vec<Response> {\n",
    "        println!(\"\\nâš¡ Processing {} requests concurrently...\", requests.len());\n",
    "        \n",
    "        // In real async code with proper concurrency:\n",
    "        // let futures: Vec<_> = requests.into_iter()\n",
    "        //     .map(|req| self.handle_request(req))\n",
    "        //     .collect();\n",
    "        // futures::future::join_all(futures).await\n",
    "        \n",
    "        // For demonstration, process sequentially\n",
    "        self.process_requests(requests).await\n",
    "    }\n",
    "    \n",
    "    fn print_stats(&self, responses: &[Response]) {\n",
    "        let total_requests = responses.len();\n",
    "        let successful = responses.iter().filter(|r| r.status == 200).count();\n",
    "        let errors = responses.iter().filter(|r| r.status >= 400).count();\n",
    "        \n",
    "        let total_time: u64 = responses.iter().map(|r| r.processing_time_ms).sum();\n",
    "        let avg_time = if total_requests > 0 { total_time / total_requests as u64 } else { 0 };\n",
    "        \n",
    "        println!(\"\\nðŸ“Š Service Statistics:\");\n",
    "        println!(\"  Total requests: {}\", total_requests);\n",
    "        println!(\"  Successful: {} ({:.1}%)\", successful, \n",
    "                (successful as f64 / total_requests as f64) * 100.0);\n",
    "        println!(\"  Errors: {} ({:.1}%)\", errors, \n",
    "                (errors as f64 / total_requests as f64) * 100.0);\n",
    "        println!(\"  Average response time: {}ms\", avg_time);\n",
    "        println!(\"  Total processing time: {}ms\", total_time);\n",
    "        println!(\"  Data store entries: {}\", self.data_store.len());\n",
    "    }\n",
    "}\n",
    "\n",
    "// Load balancer simulation\n",
    "struct AsyncLoadBalancer {\n",
    "    services: Vec<AsyncWebService>,\n",
    "    current_service: usize,\n",
    "}\n",
    "\n",
    "impl AsyncLoadBalancer {\n",
    "    fn new(service_names: Vec<String>) -> Self {\n",
    "        let services = service_names.into_iter()\n",
    "            .map(AsyncWebService::new)\n",
    "            .collect();\n",
    "        \n",
    "        AsyncLoadBalancer {\n",
    "            services,\n",
    "            current_service: 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Round-robin load balancing\n",
    "    async fn handle_request(&mut self, request: Request) -> Response {\n",
    "        let service_index = self.current_service;\n",
    "        self.current_service = (self.current_service + 1) % self.services.len();\n",
    "        \n",
    "        println!(\"ðŸ”„ Load balancer routing request {} to service {}\", \n",
    "                request.id, service_index);\n",
    "        \n",
    "        self.services[service_index].handle_request(request).await\n",
    "    }\n",
    "    \n",
    "    async fn process_requests(&mut self, requests: Vec<Request>) -> Vec<Response> {\n",
    "        let mut responses = Vec::new();\n",
    "        \n",
    "        for request in requests {\n",
    "            let response = self.handle_request(request).await;\n",
    "            responses.push(response);\n",
    "        }\n",
    "        \n",
    "        responses\n",
    "    }\n",
    "}\n",
    "\n",
    "fn async_web_service_demo() {\n",
    "    println!(\"\\n=== Async Web Service Simulation ===\");\n",
    "    \n",
    "    // Create requests\n",
    "    let requests = vec![\n",
    "        Request::new(1, \"GET\".to_string(), \"users/1\".to_string()),\n",
    "        Request::new(2, \"GET\".to_string(), \"users/2\".to_string()),\n",
    "        Request::new(3, \"POST\".to_string(), \"users/3\".to_string())\n",
    "            .with_body(\"New User Data\".to_string()),\n",
    "        Request::new(4, \"GET\".to_string(), \"posts/1\".to_string()),\n",
    "        Request::new(5, \"GET\".to_string(), \"nonexistent\".to_string()),\n",
    "        Request::new(6, \"GET\".to_string(), \"error-endpoint\".to_string()),\n",
    "        Request::new(7, \"GET\".to_string(), \"slow-endpoint\".to_string()),\n",
    "        Request::new(8, \"POST\".to_string(), \"posts/2\".to_string())\n",
    "            .with_body(\"New Post Content\".to_string()),\n",
    "    ];\n",
    "    \n",
    "    println!(\"Created {} test requests\", requests.len());\n",
    "    \n",
    "    // Note: In a real async environment, you would run this with:\n",
    "    // let mut service = AsyncWebService::new(\"TestService\".to_string());\n",
    "    // let responses = service.process_requests(requests).await;\n",
    "    // service.print_stats(&responses);\n",
    "    \n",
    "    println!(\"\\nðŸ’¡ In a real async environment, this would:\");\n",
    "    println!(\"  - Process requests concurrently\");\n",
    "    println!(\"  - Use actual async I/O operations\");\n",
    "    println!(\"  - Handle thousands of concurrent connections\");\n",
    "    println!(\"  - Provide much better performance than blocking I/O\");\n",
    "    \n",
    "    println!(\"\\nðŸ”§ Key async patterns demonstrated:\");\n",
    "    println!(\"  - Async functions with .await\");\n",
    "    println!(\"  - Error handling with Result types\");\n",
    "    println!(\"  - State management in async contexts\");\n",
    "    println!(\"  - Request/response patterns\");\n",
    "    println!(\"  - Load balancing and service distribution\");\n",
    "}\n",
    "\n",
    "async_web_service_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ§ª Active Recall Checkpoint\n",
    "\n",
    "**Test your understanding without looking back:**\n",
    "\n",
    "1. What is the Future trait and how does it work?\n",
    "2. How does async/await syntax simplify asynchronous code?\n",
    "3. What's the difference between async and threaded concurrency?\n",
    "4. How do you handle errors in async functions?\n",
    "5. What are the benefits of async programming for I/O?\n",
    "6. How do async runtimes manage task execution?\n",
    "7. When should you use async vs threads?\n",
    "8. What are common async patterns and combinators?\n",
    "\n",
    "**Write your answers below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answers:**\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n",
    "6. \n",
    "7. \n",
    "8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ¤” Reflection Prompt\n",
    "\n",
    "Consider these questions:\n",
    "\n",
    "1. **How does async programming change the way you think about I/O?**\n",
    "2. **What are the trade-offs between async and traditional blocking I/O?**\n",
    "3. **How do you design systems that effectively use async patterns?**\n",
    "4. **What challenges does async programming introduce?**\n",
    "\n",
    "Write your thoughts below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Reflections:**\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”® Preview & Connections\n",
    "\n",
    "### Coming Up Next: Macros & Metaprogramming\n",
    "\n",
    "In our next lesson, you'll learn about:\n",
    "- Declarative macros with macro_rules!\n",
    "- Procedural macros and code generation\n",
    "- Macro hygiene and best practices\n",
    "- Building domain-specific languages\n",
    "\n",
    "### How This Connects\n",
    "Async programming is essential for:\n",
    "- Building high-performance web services\n",
    "- Handling concurrent I/O operations\n",
    "- Creating scalable network applications\n",
    "- Modern systems programming\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Expected Outcomes\n",
    "\n",
    "**Self-Assessment Checklist** - Can you:\n",
    "\n",
    "- [ ] Understand the Future trait and async execution model?\n",
    "- [ ] Write async functions with proper error handling?\n",
    "- [ ] Choose between async and threaded approaches?\n",
    "- [ ] Design async systems with appropriate patterns?\n",
    "- [ ] Handle concurrent async operations effectively?\n",
    "- [ ] Understand async runtime concepts?\n",
    "- [ ] Apply async programming to real-world problems?\n",
    "\n",
    "If you checked all boxes, excellent! You've mastered async programming fundamentals.\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ‰ Exceptional Mastery!** You now understand how to build high-performance async applications in Rust!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
